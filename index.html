<section class="bio card">
  <h2>Hi, I'm Vardhan Seepala</h2>
  <p><strong>Lead Data Engineer | Cloud & Big Data Architect | Streaming Pipelines | MLOps | AI-Driven Platforms</strong></p>
  <p>Welcome to my portfolio. I'm a Lead Data Engineer with 5+ years of experience designing, building, and optimizing data platforms that deliver business value at scale. I specialize in building real-time and batch data pipelines, automating cloud infrastructure, deploying machine learning models in production, and translating complex requirements into secure, maintainable data solutions.</p>
  <hr>
  
  <h3>What I Do Best</h3>
  <ul>
    <li>Architect end-to-end cloud-native data solutions across GCP, Azure, and AWS</li>
    <li>Design high-volume streaming pipelines with Apache Beam, Kafka, and Dataflow</li>
    <li>Automate data ingestion, transformation, and AI model deployment at scale</li>
    <li>Optimize ETL/ELT pipelines for cost, latency, and reliability</li>
    <li>Champion data quality, governance, and analytics enablement</li>
    <li>Mentor cross-functional teams in adopting best practices for modern data platforms</li>
  </ul>
  <hr>

  <h3>Experience Snapshot</h3>
  
  <h4>Lead Data Engineer @ Viral Nation (Jun 2023 – Present)</h4>
  <ul>
    <li>Designed CDC pipelines (Cloud SQL → BigQuery) using GCP Datastream; reduced transformation overhead by 40%</li>
    <li>Automated infrastructure setup via Terraform with private VPC provisioning</li>
    <li>Developed real-time Dataflow pipelines with Apache Beam for MongoDB/Postgres → BigQuery ingestion</li>
    <li>Unified 10+ sources into DBT semantic layers; reduced analytics errors by 80%</li>
    <li>Engineered PySpark pipelines in Azure Synapse for campaign analytics with Looker dashboards</li>
    <li>Led MLOps deployments via Azure ML Studio & Kubernetes, reducing time-to-market by 35%</li>
    <li>Built Kafka-based model-serving pipelines for brand detection and profanity filtering (1M+ daily events)</li>
  </ul>

  <h4>Data Engineer Co-Op @ BDO (Jan 2023 – Apr 2023)</h4>
  <ul>
    <li>Rebuilt ADF pipelines, cutting processing time by 30% (13 → 9 hours)</li>
    <li>Built real-time dashboards integrating digital twin & MQTT metrics via Power BI</li>
    <li>Automated Azure Data Explorer queries using dynamic KQL generation</li>
  </ul>

  <h4>Senior Software Engineer @ Oracle Cerner (2019 – 2021)</h4>
  <ul>
    <li>Designed cost-optimized AWS EMR data pipelines serving 10K+ patients daily</li>
    <li>Automated CloudFormation stacks for IAM roles; reduced provisioning errors by 90%</li>
    <li>Cut testing time by 70% with Java/Python test automation</li>
    <li>Standardized international healthcare data across microservice APIs</li>
  </ul>

  <h4>DevOps Engineering Intern @ Sigmoid (2019)</h4>
  <ul>
    <li>Built Datadog/Elasticsearch dashboards reducing AWS cluster downtime by 50%</li>
    <li>Created PoC demos for clients that cut cluster costs by 20%</li>
  </ul>
  <hr>

  <h3>Education</h3>
  <ul>
    <li>Master of Applied Computing – University of Windsor, Canada</li>
    <li>Bachelor of Engineering in Computer Science – Sir MVIT, India</li>
  </ul>
  <hr>

  <h3>Skills & Tools</h3>
  <ul>
    <li><strong>Languages:</strong> Python, Java, SQL, Terraform, KQL, PySpark, TypeScript</li>
    <li><strong>Data Platforms:</strong> GCP (BigQuery, Dataflow, Datastream), Azure (ADF, Databricks, Synapse), AWS (EMR, Lambda, S3)</li>
    <li><strong>Orchestration:</strong> Apache Beam, Airflow, Azure ML Studio</li>
    <li><strong>DevOps & Infra:</strong> Docker, Kubernetes, GitHub Actions, CloudFormation</li>
    <li><strong>Visualization:</strong> Looker, Power BI</li>
    <li><strong>Databases:</strong> PostgreSQL, MS-SQL, MongoDB, NoSQL</li>
    <li><strong>Methodologies:</strong> Agile, Scrum, CI/CD, IaC</li>
  </ul>
  <hr>

  <h3>Resume & Contact</h3>
  <ul>
    <li><a href="mailto:seepalavardhan98@gmail.com">View My Resume</a> or request it via email</li>
    <li>LinkedIn: <a href="https://www.linkedin.com/in/vardhan-seepala-71179710b" target="_blank">linkedin.com/in/vardhan-seepala-71179710b</a></li>
    <li>GitHub: <a href="https://github.com/seepala98" target="_blank">github.com/seepala98</a></li>
    <li>Email: seepalavardhan98 @gmail.com</li>
  </ul>
  <hr>

  <h3>Let’s Connect</h3>
  <p>I'm actively exploring opportunities where I can lead or contribute to data platforms powering intelligent products. If you're building in cloud, AI, or data infrastructure and need someone who can architect and execute at scale—let’s talk.</p>
  <p>Feel free to fork or follow for upcoming projects and case studies.</p>
</section>

<section class="data-visualization">
    <h2>My Language Toolkit</h2>
    <div class="card">
        <canvas id="language-chart"></canvas>
    </div>
</section>

<section class="github-repos">
  <h2>Recent GitHub Projects</h2>
  <div id="github-repos-container"></div>
</section>

<section class="latest-posts">
  <h2>Latest Blog Posts</h2>
  <div class="card">
      <ul>
        {% for post in site.posts limit:5 %}
          <li>
            <a href="{{ post.url }}">{{ post.title }}</a>
            <span>{{ post.date | date: "%B %d, %Y" }}</span>
          </li>
        {% endfor %}
      </ul>
  </div>
</section>

<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
<script>
  async function fetchData() {
    const username = '{{ site.author.github }}';
    const response = await fetch(`https://api.github.com/users/${username}/repos?per_page=100`);
    const repos = await response.json();

    // --- Process for Language Chart ---
    const languageCounts = repos.reduce((acc, repo) => {
        if (repo.language) {
            acc[repo.language] = (acc[repo.language] || 0) + 1;
        }
        return acc;
    }, {});

    const chartData = {
        labels: Object.keys(languageCounts),
        datasets: [{
            label: 'Repositories by Language',
            data: Object.values(languageCounts),
            backgroundColor: '#00a8ff',
            borderColor: '#2c2c2c',
            borderWidth: 2
        }]
    };

    const chartCtx = document.getElementById('language-chart').getContext('2d');
    new Chart(chartCtx, {
        type: 'bar',
        data: chartData,
        options: {
            scales: {
                y: {
                    beginAtZero: true
                }
            }
        }
    });

    // --- Process for Repo Cards ---
    const sortedRepos = repos.sort((a, b) => new Date(b.pushed_at) - new Date(a.pushed_at)).slice(0, 5);
    const container = document.getElementById('github-repos-container');

    sortedRepos.forEach(repo => {
      const repoEl = document.createElement('div');
      repoEl.classList.add('card', 'repo');
      repoEl.innerHTML = `
        <h3><a href="${repo.html_url}" target="_blank">${repo.name}</a></h3>
        <p>${repo.description || 'No description available.'}</p>
        <p class="repo-meta"><strong>Language:</strong> ${repo.language || 'N/A'} | <strong>Stars:</strong> ${repo.stargazers_count}</p>
      `;
      container.appendChild(repoEl);
    });
  }

  fetchData();
</script>
