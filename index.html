---
layout: default
title: Home
---

<section class="bio card fade-in-section">
  <h2>👋 Hi, I'm Vardhan Seepala</h2>
  <p class="tagline"><strong>🚀 Lead Data Engineer | ☁️ Cloud & Big Data Architect | ⚡ Streaming Pipelines | 🤖 MLOps | 🧠 AI-Driven Platforms</strong></p>
  <p>Welcome to my portfolio, where it's all about <strong>All Things Data</strong>! I'm an <strong>Experience Data Nerd</strong> with 5+ years of experience designing, building, and optimizing data platforms that deliver business value at scale. I specialize in building real-time and batch data pipelines, automating cloud infrastructure, deploying machine learning models in production, and translating complex requirements into secure, maintainable data solutions.</p>
  <hr>
  
  <h3>What I Do Best ✨</h3>
  <ul>
    <li>Architect end-to-end cloud-native data solutions across GCP, Azure, and AWS</li>
    <li>Design high-volume streaming pipelines with Apache Beam, Kafka, and Dataflow</li>
    <li>Automate data ingestion, transformation, and AI model deployment at scale</li>
    <li>Optimize ETL/ELT pipelines for cost, latency, and reliability</li>
    <li>Champion data quality, governance, and analytics enablement</li>
    <li>Mentor cross-functional teams in adopting best practices for modern data platforms</li>
  </ul>
</section>

<div class="main-grid">

  <!-- Experience Section -->
  <section class="experience-section card fade-in-section">
    <h2>Experience Snapshot 💼</h2>
    
    <div class="job-entry">
      <h4>Lead Data Engineer @ Viral Nation (Jun 2023 – Present)</h4>
      <ul>
        <li>Designed CDC pipelines (Cloud SQL → BigQuery) using GCP Datastream; reduced transformation overhead by 40%</li>
        <li>Automated infrastructure setup via Terraform with private VPC provisioning</li>
        <li>Developed real-time Dataflow pipelines with Apache Beam for MongoDB/Postgres → BigQuery ingestion</li>
        <li>Unified 10+ sources into DBT semantic layers; reduced analytics errors by 80%</li>
        <li>Engineered PySpark pipelines in Azure Synapse for campaign analytics with Looker dashboards</li>
        <li>Led MLOps deployments via Azure ML Studio & Kubernetes, reducing time-to-market by 35%</li>
        <li>Built Kafka-based model-serving pipelines for brand detection and profanity filtering (1M+ daily events)</li>
      </ul>
    </div>

    <div class="job-entry">
      <h4>Data Engineer Co-Op @ BDO (Jan 2023 – Apr 2023)</h4>
      <ul>
        <li>Rebuilt ADF pipelines, cutting processing time by 30% (13 → 9 hours)</li>
        <li>Built real-time dashboards integrating digital twin & MQTT metrics via Power BI</li>
        <li>Automated Azure Data Explorer queries using dynamic KQL generation</li>
      </ul>
    </div>

    <div class="job-entry">
      <h4>Senior Software Engineer @ Oracle Cerner (2019 – 2021)</h4>
      <ul>
          <li>Designed cost-optimized AWS EMR data pipelines serving 10K+ patients daily</li>
          <li>Automated CloudFormation stacks for IAM roles; reduced provisioning errors by 90%</li>
          <li>Cut testing time by 70% with Java/Python test automation</li>
          <li>Standardized international healthcare data across microservice APIs</li>
      </ul>
    </div>

    <div class="job-entry">
      <h4>DevOps Engineering Intern @ Sigmoid (2019)</h4>
      <ul>
          <li>Built Datadog/Elasticsearch dashboards reducing AWS cluster downtime by 50%</li>
          <li>Created PoC demos for clients that cut cluster costs by 20%</li>
      </ul>
    </div>
  </section>

  <div class="skills-education-grid">
    <!-- Skills Section -->
    <section class="skills-section card fade-in-section">
      <h2>Skills & Tools 🛠️</h2>
      <ul>
        <li><i class="fas fa-code"></i> <strong>Languages:</strong> Python, Java, SQL, Terraform, KQL, PySpark, TypeScript</li>
        <li><i class="fas fa-cloud"></i> <strong>Data Platforms:</strong> GCP (BigQuery, Dataflow, Datastream), Azure (ADF, Databricks, Synapse), AWS (EMR, Lambda, S3)</li>
        <li><i class="fas fa-project-diagram"></i> <strong>Orchestration:</strong> Apache Beam, Airflow, Azure ML Studio</li>
        <li><i class="fas fa-cogs"></i> <strong>DevOps & Infra:</strong> Docker, Kubernetes, GitHub Actions, CloudFormation</li>
        <li><i class="fas fa-chart-bar"></i> <strong>Visualization:</strong> Looker, Power BI</li>
        <li><i class="fas fa-database"></i> <strong>Databases:</strong> PostgreSQL, MS-SQL, MongoDB, NoSQL</li>
        <li><i class="fas fa-sitemap"></i> <strong>Methodologies:</strong> Agile, Scrum, CI/CD, IaC</li>
      </ul>
    </section>

    <!-- Education Section -->
    <section class="education-section card fade-in-section">
      <h2>Education 🎓</h2>
      <ul>
        <li><i class="fas fa-graduation-cap"></i> Master of Applied Computing – University of Windsor, Canada</li>
        <li><i class="fas fa-graduation-cap"></i> Bachelor of Engineering in Computer Science – Sir MVIT, India</li>
      </ul>
    </section>
  </div>

</div>

<section class="data-visualization fade-in-section">
    <h2>My Language Toolkit 📊</h2>
    <div class="card">
        <canvas id="language-chart"></canvas>
    </div>
</section>

<section class="github-repos fade-in-section">
  <h2>Recent GitHub Projects 💻</h2>
  <div id="github-repos-container"></div>
</section>

<section class="latest-posts fade-in-section">
  <h2>Latest Blog Posts 📝</h2>
  <div class="card">
      <ul>
        {% for post in site.posts limit:5 %}
          <li>
            <a href="{{ post.url }}">{{ post.title }}</a>
            <span>{{ post.date | date: "%B %d, %Y" }}</span>
          </li>
        {% endfor %}
      </ul>
  </div>
</section>

<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
<script>
  async function fetchData() {
    const username = '{{ site.author.github }}';
    const response = await fetch(`https://api.github.com/users/${username}/repos?per_page=100`);
    const repos = await response.json();

    // --- Process for Language Chart ---
    const languageCounts = repos.reduce((acc, repo) => {
        if (repo.language) {
            acc[repo.language] = (acc[repo.language] || 0) + 1;
        }
        return acc;
    }, {});

    const chartData = {
        labels: Object.keys(languageCounts),
        datasets: [{
            label: 'Repositories by Language',
            data: Object.values(languageCounts),
            backgroundColor: '#00a8ff',
            borderColor: '#2c2c2c',
            borderWidth: 2
        }]
    };

    const chartCtx = document.getElementById('language-chart').getContext('2d');
    new Chart(chartCtx, {
        type: 'bar',
        data: chartData,
        options: {
            scales: {
                y: {
                    beginAtZero: true
                }
            }
        }
    });

    // --- Process for Repo Cards ---
    const sortedRepos = repos.sort((a, b) => new Date(b.pushed_at) - new Date(a.pushed_at)).slice(0, 5);
    const container = document.getElementById('github-repos-container');

    sortedRepos.forEach(repo => {
      const repoEl = document.createElement('div');
      repoEl.classList.add('card', 'repo');
      repoEl.innerHTML = `
        <h3><a href="${repo.html_url}" target="_blank">${repo.name}</a></h3>
        <p>${repo.description || 'No description available.'}</p>
        <p class="repo-meta"><strong>Language:</strong> ${repo.language || 'N/A'}</p>
      `;
      container.appendChild(repoEl);
    });
  }

  fetchData();
</script>
